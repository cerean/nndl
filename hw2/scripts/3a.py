# -*- coding: utf-8 -*-
"""3a.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13JENpAeWrBNfmmHPRcbH9iU5cbC6noTv

## CSc 84020 Neural Networks and Deep Learning, Spring 2021
##### Homework 2 (3a)
##### Andrea Ceres and Shao Liu

##### **Load library**
"""

# Commented out IPython magic to ensure Python compatibility.
import glob
import os
import numpy as np
import keras
from keras import layers
from urllib import request
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import pandas as pd
import pylab
from pandas.plotting import scatter_matrix
from pandas import set_option
import time
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
# %matplotlib inline

print(tf.__version__)

"""##### **Load Data from Google Drive**"""

from google.colab import drive
drive.mount('/content/drive')

# critters (6 classes)
critters = ['ant', 'bee', 'butterfly', 'mosquito', 'scorpion', 
           'spider']

# birds (6 classes)
birds = ['bird', 'duck', 'flamingo', 'owl', 'parrot', 
           'penguin']

# ocean animals (8 classes)
ocean_animals = ['crab', 'dolphin', 'fish', 'lobster', 'octopus', 
           'sea%20turtle', 'shark', 'whale']

# land mammals (22 classes)
land_mammals = ['bear', 'camel', 'cat', 'cow', 'dog', 
           'elephant', 'giraffe', 'hedgehog', 'horse', 'kangaroo', 
           'lion', 'monkey', 'mouse', 'panda', 'pig', 
           'rabbit', 'raccoon', 'rhinoceros', 'sheep', 'squirrel', 
           'tiger', 'zebra']

# all animals (47 classes)
all_animals = ['ant', 'bat', 'bear', 'bee', 'bird', 
           'butterfly', 'camel', 'cat', 'cow', 'crab', 
           'crocodile', 'dog', 'dolphin', 'duck', 'elephant', 
           'fish', 'flamingo', 'frog', 'giraffe', 'hedgehog', 
           'horse', 'kangaroo', 'lion', 'lobster', 'monkey', 
           'mosquito', 'mouse', 'octopus', 'owl', 'panda', 
           'parrot', 'penguin', 'pig', 'rabbit', 'raccoon', 
           'rhinoceros', 'scorpion', 'sea_20turtle', 'shark', 'sheep', 
           'snail', 'snake', 'spider', 'squirrel',  'tiger', 
           'whale', 'zebra']

classes = critters
CLASS_SAMPLE_MAX = 25000
DATA_DIR = '/content/drive/My Drive/Colab Notebooks/NNDL/HW2/data/'

def load_bitmaps(data_dir=DATA_DIR, class_sample_max=CLASS_SAMPLE_MAX):
    class_files = []
    for c in classes:
        print(c, end=' ')
        class_files.append(os.path.join(DATA_DIR, c + '.npy'))
    class_files.sort()
  
    X = np.empty([0,784])
    y = np.empty([0])

    print()
    for id, class_file in enumerate(class_files):
        print(id, end=' ')
        loaded_data = np.load(class_file)
        loaded_data = loaded_data[0:CLASS_SAMPLE_MAX, :]
        labels = np.full(loaded_data.shape[0],id)
        
        X = np.concatenate((X, loaded_data), axis = 0)
        y = np.append(y, labels)

    return X, y

start = time.time()
X, y = load_bitmaps()
print(f'\nLoading time: %.3f' % int(time.time() - start), 'seconds')
print(X.shape)
print(y.shape)
print(y[-CLASS_SAMPLE_MAX-5:-CLASS_SAMPLE_MAX+5])

"""##### **Data sample**"""

id = 20000
plt.imshow(X[id].reshape(28,28)) 
print(classes[int(y[id].item())])

set_option('display.max_columns', 64)
# plt.style.use('seaborn-white')

"""##### **1. Printing the shape of the data**"""

# Create pandas dataframe 
Y = y.reshape(150000,1)
df = np.append(X,Y,1)
df = pd.DataFrame(df)
# 1. Printing the shape of the data
print(df.shape)

"""##### **2. Printing the data**"""

print(df.head(20))

# Only show the 28 pixels in center because most of the pixels are zeros in other areas.
features = list(df.columns[391:419])
df_mid = df[features]
print(df_mid)

"""##### **3. Printing the descriptive statistics**"""

# 3. Printing the descriptive statistics
print(df.describe())

# Show the 28 pixels in center
print(df_mid.describe())

"""##### **4. Printing the class distribution**"""

# 4. Printing the class distribution
print(df.groupby(784).size())

"""##### **5. Printing the data types of the features.**"""

#  5. Printing the data types of the features.
print(df.dtypes)

"""##### **6. Printing the Pearson Correlation.**"""

# 6. Printing the Pearson Correlation.
# Only use the 28 pixels in center because most of the pixels are zeros in other areas.
features = list(df.columns[391:419])
df_mid = df[features]
print(df_mid.corr(method='pearson'))

"""##### **7. Printing the skewness of the dataset.**"""

# 7. Printing the skewness of the dataset (28 attributes in center).
print(df_mid.skew())

"""##### **8. Histograms of all features**"""

# 8. Histograms of all features
pylab.rcParams['figure.figsize'] = (10,20)
df_mid.hist(color='cyan', layout=(16,5))
plt.tight_layout()
plt.show()

"""##### **9. Scatter Matrix**"""

# 9. Scatter Matrix
pylab.rcParams['figure.figsize'] = (12,12)
scatter_matrix(df_mid[[400,401,402,403,418]],alpha=0.05)
plt.tight_layout()
plt.show()

"""##### **10. Density plot for each feature.**"""

# 10. Density plot for each feature.
# pylab.rcParams['figure.figsize'] = (10,25)
# print(df_mid)
df_mid.select_dtypes('float').plot(kind='hist', subplots=True, layout=(20,5), figsize=(25,35), sharex=False, sharey = False, fontsize=5, color='steelblue')
plt.tight_layout()
plt.show()

"""##### **11. Correlation Matrix Plot**"""

# 11. Correlation Matrix Plot
pylab.rcParams['figure.figsize'] = (10,10)
correlations = df_mid.corr()
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(correlations, vmin = -1, vmax = 1, cmap='viridis')
fig.colorbar(cax)
ticks = np.arange(0,len(df_mid.columns),1)
ax.set_xticks(ticks)
ax.set_yticks(ticks)
ax.set_xticklabels(df_mid.columns, rotation=90)
ax.set_yticklabels(df_mid.columns, rotation=0)
plt.title('Correlation matrix plot of 28 attributes in the center\n\n')
plt.show()

"""##### **12. Classification: split the dataset into train, validate and test**"""

# Classification: split the dataset into train, validate and test
test_size = 0.10
val_size = 0.22
seed = 84020
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=test_size, random_state=seed)
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.22, random_state=seed)

# Training data
unique, counts = np.unique(Y_train, return_counts=True)
pylab.rcParams['figure.figsize'] = (10,5)
plt.bar(critters, counts)
plt.title('Number of samples per class in the training set\n')
plt.ylabel('Count\n')
plt.xlabel('\nClass')
plt.show()

# Validation data
unique, counts = np.unique(Y_val, return_counts=True)
pylab.rcParams['figure.figsize'] = (10,5)
plt.bar(critters, counts)
plt.title('Number of samples per class in the validation set\n')
plt.ylabel('Count\n')
plt.xlabel('\nClass')
plt.show()

# Testing data
unique, counts = np.unique(Y_test, return_counts=True)
pylab.rcParams['figure.figsize'] = (10,5)
plt.bar(critters, counts)
plt.title('Number of samples per class in the testing set\n')
plt.ylabel('Count\n')
plt.xlabel('\nClass')
plt.show()

# Use small set of 6 classes for Spot Check Algorithms
classes = critters
CLASS_SAMPLE_MAX = 1000
DATA_DIR = '/content/drive/My Drive/Colab Notebooks/NNDL/HW2/data/'

start = time.time()
X, y = load_bitmaps()
print(f'\nLoading time: %.3f' % int(time.time() - start), 'seconds')
print(X.shape)
print(y.shape)
print(y[-CLASS_SAMPLE_MAX-5:-CLASS_SAMPLE_MAX+5])

test_size = 0.10
val_size = 0.2
seed = 46
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=test_size, random_state=seed)
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=val_size/(1-test_size), random_state=seed)

unique, counts = np.unique(Y_train, return_counts=True)
pylab.rcParams['figure.figsize'] = (10,5)
plt.bar(critters, counts)
plt.title('Number of samples per class in the training set\n')
plt.ylabel('Count\n')
plt.xlabel('\nClass')
plt.show()

"""##### **13. Spot-Check Algorithms**"""

# Spot-Check Algorithms
start = time.time()
models = []
models.append(('LR', LogisticRegression(C=0.01,solver='sag')))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier(random_state=seed)))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))
# evaluate each model in turn
results = []
names = []
for name, model in models:
  kfold = KFold(n_splits=10,random_state=seed, shuffle=True)
  # cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='f1_micro')
  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
  results.append(cv_results)
  names.append(name)
  msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
  print(msg)

"""##### **14. Compare Algorithms**"""

# Compare Algorithms
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
c1 = 'steelblue'
c2 = 'blue'
c3 = 'lightblue'
box = plt.boxplot(results, patch_artist=True, 
                     boxprops=dict(facecolor=c1, color=c1), 
                     capprops=dict(color=c3), 
                     whiskerprops=dict(color=c3), 
                     flierprops=dict(color=c3, markeredgecolor=c3), 
                     medianprops=dict(color=c2))
ax.set_xticklabels(names)
plt.ylabel('Accuracy\n')
plt.xlabel('\nAlgorithm')
plt.show()
plt.show()

"""##### **15. Make predictions on validation dataset**"""

# Make predictions on validation dataset
knn = KNeighborsClassifier()
knn.fit(X_train,Y_train)
pred_knn = knn.predict(X_val)
print('accuracy:',accuracy_score(Y_val, pred_knn))
print('confusion matrix:\n',confusion_matrix(Y_val, pred_knn))

"""##### **16. Classification report**"""

print('classification report:\n', classification_report(Y_val, pred_knn))