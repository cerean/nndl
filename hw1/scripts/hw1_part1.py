# -*- coding: utf-8 -*-
"""HW1_part1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bzXcZDIj-i3HJ32RqB6LWSuuE4VMB_t9

# CS 84020 Neural Networks and Deep Learning
#### Homework 1
#### Andrea Ceres and Shao Liu

# **PART1**

# Listing 1
#### Load libraries. Load the Wisconsin Diagnostic Breast Cancer dataset.
**Analysis**</p>
The Wisconsin Diagnostic Breast Cancer dataset (WDBC) can be found on the UC Irvine Machine Learning Repository website.<sup>1</sup> This dataset originates from University of Wisconsin and dates back to the early 1990s. For each instance, an image of fine needle aspirate (FNA) of breast mass was digitized. From each image, characteristics of the cell nuclei present were quantified and summarized as dataset features. We infer the attribute names from the WDBC dataset description file and provide them upon loading the file.<sup>2</sup> The mean of all of the values, the standard error, and the mean of the three largest values (namely, the worst finding) were calculated for each of ten different measurements on the aspirated cells visible in each image. The target `diagnosis` labels the pathology of the breast mass biopsy--benign or malignant.</p>
<table>
  <tr>
    <td>Benign biopsy image</td>
    <td>Malignant biopsy image<sup>3</sup></td>
  </tr>
  <tr>
    <td><img src="ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images/92_5277.gif" width=275 height=175></td>
    <td><img src="ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images/92_6125.gif" width=275 height=175></td>
  </tr>
 </table></p>
<sup>1</sup>WDBC dataset source: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29</p>
<sup>2</sup>WDBC dataset description: http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names</p>
<sup>3</sup>WDBC biopsy images: ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images/

a) Load libraries.
"""

# Load libraries
from pandas import read_csv, set_option
from pandas.plotting import scatter_matrix
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

# Set options
set_option('display.max_columns', 32)
# plt.style.use('seaborn-talk')
plt.style.use('seaborn-white')

"""b) Load the dataset."""

# Load dataset
filename = 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
colnames = ['id', 'diagnosis', 
         'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 
         'smoothness_mean', 'compactness_mean', 'concavity_mean', 
         'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', 
         'radius_se', 'texture_se', 'perimeter_se', 'area_se', 
         'smoothness_se', 'compactness_se', 'concavity_se', 
         'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 
         'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 
         'smoothness_worst', 'compactness_worst', 'concavity_worst', 
         'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']
dataset = read_csv(filename, names=colnames, header=None)

"""# Listing 2
#### Dimensions of the dataset. Peek at the data itself. Statistical summary of all attributes. Breakdown of the data by the class variable.
**Analysis**</p>
The WDBC dataset has 569 records with no missing values. The unique `id` identifier, the binary `diagnosis` target ('B' or 'M'), and the ten sets (mean, standard error, and worst) of real-valued features total 32 columns. We dropped the `id` column as this attribute is not pertinent to our analysis. We encoded the target column `diagnosis` to the binary mapping `{'B':0, 'M':1}`. Based on the aforementioned derivation of the worst (largest) attribute for a given measurement, the dataset, as expected, consistently shows each mean attribute to be lower than the corresponding worst attribute. Furthermore, the standard deviations of each mean attribute is consistently lower than that of the worst. Because the worst is derived from a smaller sample (only the worst three nuclei), a larger standard deviation to that of the mean attribute is expected and is indeed reflected in the summary description of the dataset. All values are non-negative. The class distribution is imbalanced, with 357 benign and 212 malignant.

a) Print the shape of the dataset.
"""

# shape
print(dataset.shape)

# confirm unique identifier count
print(dataset['id'].nunique())

# drop `id` identifier
dataset = dataset.drop(['id'], 1)

# new shape
print(dataset.shape)

"""b) Print the first few rows of the dataset."""

# head
print(dataset.head())

"""c) Print the statistical descriptions of the dataset."""

# descriptions
dataset.describe()

"""d) Print the class distribution in the dataset."""

# recode target labels to 0 and 1
dataset['diagnosis'] = dataset['diagnosis'].map({'B':0, 'M':1})
dataset.head(3)

# class distribution
print(dataset.groupby('diagnosis').size())

"""# Listing 3
#### Univariate plots to better understand each attribute. Multivariate plots to better understand the relationships between attributes.
**Analysis**</p>
Most of the features are positively-skewed, having the majority of outliers at the highest values. Because worst is defined here as the mean of the three largest values, it is plausible that most outliers in a dataset imbalanced toward the benign target reflect higher, not lower, values. All features show distinct but overlapping clusters for the target labels, benign or malignant. Radius, perimeter, and area have a very strong, linear, positive correlation. This is a clear indication of dependence: given a radius, one can calculate the area and circumference of a circle (the approximate shape of a cell nucleus). As a result, dropping two of these three features should be considered. Texture, compactness, concavity, and concave points also have a positive correlation with each other and with the aforementioned. Symmetry and fractal dimension provide the weakest association with any of the features, except in the worst cases whereby there are positive correlations among the worst means.

a) Univariate plot.
"""

# box and whisker plots
dataset.select_dtypes('float').plot(kind='box', subplots=True, layout=(10,5), figsize=(15,35), 
             sharex=False, sharey=False, fontsize=10, color='hotpink')
plt.tight_layout()
plt.show()

"""b) Visualize the dataset using histogram plots."""

# histograms
s = dataset.select_dtypes('float').hist(figsize=(20,20), bins=20, grid=False, color='deeppink', alpha=0.3)
plt.tight_layout()
plt.show()

"""c) Visualize the dataset using scatter plots."""

# scatter plot matrix
features = list(dataset.columns[1:11])
color_dic = {0:'mistyrose', 1:'hotpink'}
colors = dataset['diagnosis'].map(lambda x: color_dic.get(x))
sm = scatter_matrix(dataset[features], c=colors, alpha=0.4, figsize=((15,15)),
                    hist_kwds={'color':['deeppink'], 'alpha':0.3, 'bins':20})
plt.suptitle('Mean Attribute Pair Plots')

# Change the label rotation
[s.xaxis.label.set_rotation(90) for s in sm.reshape(-1)]
[s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]

# Offset the label when rotating to prevent overlap of figure
[s.get_yaxis().set_label_coords(-0.65,0.5) for s in sm.reshape(-1)]

# Hide all ticks
[s.set_xticks(()) for s in sm.reshape(-1)]
[s.set_yticks(()) for s in sm.reshape(-1)]

plt.show()

# scatter plot matrix
features = list(dataset.columns[11:21])
color_dic = {0:'mistyrose', 1:'hotpink'}
colors = dataset['diagnosis'].map(lambda x: color_dic.get(x))
sm = scatter_matrix(dataset[features], c=colors, alpha=0.4, figsize=((15,15)),
                    hist_kwds={'color':['deeppink'], 'alpha':0.3, 'bins':20})
plt.suptitle('Standard Error Attribute Pair Plots')

# Change the label rotation
[s.xaxis.label.set_rotation(90) for s in sm.reshape(-1)]
[s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]

# Offset the label when rotating to prevent overlap of figure
[s.get_yaxis().set_label_coords(-0.65,0.5) for s in sm.reshape(-1)]

# Hide all ticks
[s.set_xticks(()) for s in sm.reshape(-1)]
[s.set_yticks(()) for s in sm.reshape(-1)]

plt.show()

# scatter plot matrix
features = list(dataset.columns[21:])
color_dic = {0:'mistyrose', 1:'hotpink'}
colors = dataset['diagnosis'].map(lambda x: color_dic.get(x))
sm = scatter_matrix(dataset[features], c=colors, alpha=0.4, figsize=((15,15)),
                    hist_kwds={'color':['deeppink'], 'alpha':0.3, 'bins':20})
plt.suptitle('Worst Attribute Pair Plots')

# Change the label rotation
[s.xaxis.label.set_rotation(90) for s in sm.reshape(-1)]
[s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]

# Offset the label when rotating to prevent overlap of figure
[s.get_yaxis().set_label_coords(-0.65,0.5) for s in sm.reshape(-1)]

# Hide all ticks
[s.set_xticks(()) for s in sm.reshape(-1)]
[s.set_yticks(()) for s in sm.reshape(-1)]

plt.show()

"""# Listing 4
#### Separate out a validation dataset.
**Analysis**</p>
The dataset is split into 80% training and 20% validation. Six models are each fit to the training data via ten-fold cross validation. Scoring has been set to recall due to the nature of the dataset. In the case of malignancy, high recall (sensitivity) is favored over high precision (specificity). In other words, the chance a negative (benign) diagnosis is a true negative should be maximized, such that no cancer diagnosis is missed. Thus, recall is the metric used for scoring. Because the dataset is small and the target binary, the logistic regression model is set to the liblinear solver, allowing for quick convergence. 
From the algorithm comparison box plot, we can conclude that the Logistic  Regression(LR) model achieved the highest average accuracy with low variance. KNN and CART also achieved high accuracy (0.910 and 0.928). However, the best and worst score of KNN are very different( lowest accuracy of KNN is around 0.75). Moreover, half of the scores are in a large range around the mean accuracy. This means the accuracy of KNN and CART has larger variance and might not work well on validation dataset.

a) Create validation set.
"""

array= dataset.values
X = array[:,1:]
Y = array[:,0]
Y=Y.astype('int')
val_size = 0.20
seed = 7
X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=val_size, random_state=seed)

"""b) Build models (Logistic Regression (LR), Linear Discriminant Analysis (LDA), kNearest Neighbors (KNN), Classifications and Regression Trees (CART), Gaussian
Naive Bayes (NB), Support Vector Machines (SVM) and select the best model.
"""

# Spot-Check Algorithms
models = []
models.append(('LR', LogisticRegression(solver='liblinear')))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier(random_state=seed)))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))
# evaluate each model in turn
results = []
names = []
for name, model in models:
  kfold = KFold(n_splits=10,random_state=seed, shuffle=True)
  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='recall')
  results.append(cv_results)
  names.append(name)
  msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
  print(msg)

"""c) Compare algorithms."""

# Compare Algorithms
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
c1 = 'pink'
c2 = 'deeppink'
c3 = 'lightpink'
box = plt.boxplot(results, patch_artist=True, 
                     boxprops=dict(facecolor=c1, color=c1), 
                     capprops=dict(color=c3), 
                     whiskerprops=dict(color=c3), 
                     flierprops=dict(color=c3, markeredgecolor=c3), 
                     medianprops=dict(color=c2))
ax.set_xticklabels(names)
plt.show()

"""# Listing 5
#### Make predictions on the validation dataset.
**Analysis**</p>
After we tested all the trained model on validation data, we found the Linear Discriminant Analysis(LDA) and NB(GaussianNB)achieved the highest score(0.956) which is even higher than their training accuracy. However, the model (CART) that got 0.938 in training only got 0.928 in training only achieved 0.912 in testing. This is because the CART model is overfitting to the training dataset and cannot perform well on classification of the testing set. An interesting thing is most of the validation scores are higher than the training score. However, in most cases, the validation score should be lower than training score because training model is somehow overfitting to training data. I think the reason that we got higher validation data is because the validation dataset is small and the samples might fit to the model by coincidence. Especially for NB model, NB model only got 0.88 training accuracy but 0.956 testing accuracy. This means the validation score are not reflecting the performance of each model. One way to fix this is to create a new training and validation dataset and retrain the models. 
"""

# Make predictions on validation dataset
lr = LogisticRegression(solver='liblinear')
lr.fit(X_train, Y_train)
pred_lr = lr.predict(X_val)
print(accuracy_score(Y_val, pred_lr))
print(confusion_matrix(Y_val, pred_lr))
print(classification_report(Y_val, pred_lr))

def model_predict(name, model):
    model.fit(X_train, Y_train)
    pred = model.predict(X_val)
    print("%s: %f" % (name, accuracy_score(Y_val, pred)))
    print(confusion_matrix(Y_val, pred))
    print(classification_report(Y_val, pred))
    print()
    # return pred

for name, model in models:
    model_predict(name, model)